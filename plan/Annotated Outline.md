# Annotated Outline
1. CONTEXT
    1. WHY MOCAP DATA
        * In the animation and game industry, the traditional method of animation is incredibly skill, labor and time intensive. Although MOCAP often surpass generative modeling or traditional animation techniques in the naturalness of motion, it is a very expensive and time-consuming process and not feasible as a primary method of animation.
    2. WHY LONG-TERM IN-BETWEENING
        * Motion synthesis is a current, active area of research in computer graphics. However, it typically only allows a high level control such as plotting the path taken or are specialized for task-specific goals. An artist may find it useful to have more precise control on specific frames, giving it limited usefulness in an industry setting.
        * Long-term in-betweening is an application of motion synthesis that gives the artist more control and is more directly useful to artists as a tool.
    3. THESIS
        * In this project, I am focusing on reducing the labor cost of animation with a system for data-driven long-term in-betweening of a human model with a motion-graph based approach (versus deep learning).
        * Specifically: I will focus on the amount of resources required, the amount of artistic control allowed by the model, the naturalness of movement, and the precision/accuracy of the key poses (input).
2. DATA
    * I am creating the graph using MOCAP data from LAFAN1 (Ubisoft La Forge Animation Dataset) which is in the BVH file format.
3. LITERATURE
    1.  LONG-TERM IN-BETWEENING
        * Long-term in-betweening is a recently proposed task and as a result, there have not been many papers on this task. Current approaches to long-term in-betweening typically use a neural network to tween the start and end frame.
        * Two major papers in this area are: Robust Motion In-betweening, published July 2020, and Generative Tweening: Long-term Inbetweening of 3D Human Motions, published May 2020.
    2. MOTION GRAPH
        * Motion graphs is a method for creating realistic, controllable motion proposed in a 2002 paper titled Motion Graphs. Motion graphs are directed graphs created on a corpus of motion capture data that stores the connections among motions. Then, motion can be generated by walking through the graph.
4. METHOD
    * Long-term in-betweening is a fairly new task being investigated and approaches to this task have involved deep learning. This makes sense as in many computer graphics tasks, deep learning techniques have superior performance to more traditional approaches. However, with all techniques come tradeoffs.
    1. TRADITIONAL VS DEEP LEARNING APPROACHES
        * For example, in computer vision, although CNNs have higher accuracy than traditional vision algorithms, this comes at the expense of the requirement of a longer processing time, a longer training time (and the associated compute resources), and the requirement of many data points to be effective.
        * If the model cannot be created beforehand and applied to a task, it would be impractical in practice. Thus, there is a place for traditional approaches to tasks when the task needs to be done quickly and accuracy is not super important.
    2. MOTION GRAPHS FOR MOTION SYNTHESIS
        * In this project, I am implementing a motion graph to compare against the performance of neural networks. Long-term in-betweening sprung from the more generic motion synthesis, and motion graph is an approach taken to synthesize motion. Therefore, utilizing motion graphs to perform long-term in-betweening is a logical step.
    3. MOTION GRAPHS FOR LONG-TERM IN-BETWEENING
        * To use motion graphs specifically for long-term in-betweening, there are two major parts:
            1. finding the nodes the are most similar to the target start and end points, and
            2. connecting the start and end nodes of the graph.
        * The first task requires an approach similar to how one connects the motion graph: for each node in the graph, compare the node with the desired node and, in this case, set the start/end node to be the node most similar to the input start/end point.
        * The second task is connecting the start and end nodes which requires a graph search. There are many papers related to graph search and those can be applied to this. However, in this project, I implemented BFS with pruning based on artist-specified values.
5. FINDINGS
    1. RESOURCES CONSUMPTION
        * I built the motion graph long-term in-betweening implementation on top of the Fairmotion motion graph implementation. The primary stages that take the most amount of time, from most amount of time to least, are: generating the motion graph, processing the motion files, and doing the graph search.
        * Generating the motion graph only needs to be done once per set of specifications, because it can be saved and reused.
        * The parameters of the graph search can also be modified to lessen the demand for time and memory by reducing the search space (which can easily get very big because the graph is strongly connected).
    2. ARTISTIC CONTROL
        * One form of artistic control is that the artist can specify the dataset. The artist can specify motions most similar to the kind of motion the artist wants to generate, and generate a graph from those motions. Additionally, the graph can be saved and reused, reducing a lot of the upfront costs after created. We can also add more motion to graphs little by little, creating varied graphs to generate the output the artist is looking for.
    3. NATURALNESS
        * Although we can use few motion files to create the motion graph, the issue with that is that the graph may not be close enough to the input/output pose as well as is not strongly connected enough. This results in a lot of interpolation or simply having no path between the selected start and end nodes. Thus, the motion will not be natural at all.
        * Much more motion data can be used to build the graph, but the drawback of this approach is the length of time and amount of compute required to create the graph and later search through it to generate the inbetweening.
    4. POSE PRECISION
        * Because the in-betweening is generated as a path between two nodes from a motion graph, the start and end poses may not be exactly like the input. However, this is simple to fix by doing a simple tween between the input poses and the start and end poses.
        * However, once again, the naturalness of this generated tween depends on how good of a fit the graph is to the desired motion.
    5. SEARCH ALGORITHM
        * The search algorithm has to consider the tradeoff between guiding the search toward a particular result balanced against unduly preventing it from considering all available options.
        * To do this, I included a parameter the artist can tune to represent the threshold for pruning the search space.
        * The graph as well has a similar parameter to balance between good transitions (low difference threshold) and having high connectivity (high difference threshold).
6 CONCLUSION
    * In conclusion, motion graphs are a good solution to long-term in-betweening, but there are a lot of caveats. It is highly dependent on whether the motion files the graph is created with is similar enough to the desired generated motion and there are many parameters that need to be tuned to get a good motion in graph generation and motion search. These are active areas of research and I believe application of the latest work in the field will further improve the efficacy of this technique and is worth looking into.

# REFERENCES
* Comparing Deep Neural Networks and Traditional Vision Algorithms in Mobile Robotics: [https://www.cs.swarthmore.edu/~meeden/cs81/f15/papers/Andy.pdf](https://www.cs.swarthmore.edu/~meeden/cs81/f15/papers/Andy.pdf)
* Motion Graphs: [https://graphics.cs.wisc.edu/Papers/2002/KGP02/mograph.pdf](https://graphics.cs.wisc.edu/Papers/2002/KGP02/mograph.pdf)
* Generative Tweening: Long-term Inbetweening of 3D Human Motions: [https://arxiv.org/pdf/2005.08891.pdf](https://arxiv.org/pdf/2005.08891.pdf)
* Robust Motion In-betweening: [https://static-wordpress.akamaized.net/montreal.ubisoft.com/wp-content/uploads/2020/07/09155337/RobustMotionInbetweening.pdf](https://static-wordpress.akamaized.net/montreal.ubisoft.com/wp-content/uploads/2020/07/09155337/RobustMotionInbetweening.pdf)
* Fairmotion: [https://github.com/facebookresearch/fairmotion ](https://github.com/facebookresearch/fairmotion )
