# Data Source
Eunice Chan

My project is focused on generating frames of 2D hand-drawn animation from frames of 2D hand-drawn animation. As a  result, the data I need is 2D hand-drawn animated videos. To find these data sources, I looked into public domain animated videos to give myself the most freedom to do as I wish with the data. For these purposes, I sifted through the Perlinger archives, the Library of Congress archives, and the Public Domain Review archive for 2D hand-drawn animated videos and added it to the data collection.

From the short clips of each video I watched, I got a sense of the kind of animation present. The animated videos I downloaded are from the early days of animation in the United States and thus reflect this. Most notably, this has a very simplified, old-American-cartoon artstyle and a lot of artifacts from the style of animation such as flickering lights and shadows. Most of the videos are not colored as well, which is an artifact of the time it came from.

There are a lot of shortcuts taken in the animation due to how laborious it is, such as sliding a motionless character across a scene instead of adding animation to the character as it moves around. Another common shortcut is the splicing of live action sequences to reduce the amount of animation needed. I specifically ignored videos that were more live action than animated and videos that were essentially an  image presentation being narrated over.

If the quantity of 2D hand-drawn animated videos are not sufficient for training purposes, I intend to supplement the animated videos with natural videos as well as modified versions of the 2D hand-drawn animated videos: changing the aspect ratio, cropping the videos,  adjusting contrast, changing the colors, applying edge detection algorithm, changing the art style (with something like StyleGAN), and so on. However, some of these mentioned modifications may not be applicable depending on how I define the scope of the project. For example, since many of the animations I have collected so far are in black and white, I may choose to limit the model to generating black and white frames.

One thing I am interested in exploring to supplement my exploration of video generation of 2D hand-drawn animation is the application of  the models on 2D animated, 3D animated, and natural videos. I want to apply the models used for natural videos on 2D and 3D animated and see how well it generalizes as well as apply the models trained for 2D on 3D animated and natural videos to see what specific features are learned to do video generation for 2D. By applying the models trained for two different purposes on the three sets of input, I can better see the biases, quirks, and limitations of the models.

For these purposes, I would need a dataset of natural videos and a dataset of 3D animated videos. The dataset of natural videos should be relatively easy to acquire as there are many research papers uilizing video dataset. I plan on using the BAIR Robot Pushing Dataset, Kinetics-600 Dataset, and potentially others (such as the Berkeley Video Segmentation Dataset). As the videos do not need to be labeled for my purposes, there are myriad sources I can use (including creating  my own video footage). 3D animated videos would be a little bit more difficult to come by and I have not looked too much into it. Since this is a supplementary part of the project that I may not end up doing, I've decided to look for potential data sources at a later stage when I have a clearer understanding of whether such comparisons would be relevant or be valuable for my purposes.
